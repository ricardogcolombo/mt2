\section{Introduccion Teorica}
En el ambiente de la informatica en general se ha visto un incremento considerable en diferentes tecnicas que buscan tomar elementos del mundo como lo conocemos y darle una interpretación que hasta no hace mucho no era concebible para una maquina. Tales son los casos de reconocimiento de personas en imagenes con su posterior "etiquetado" (Facebook o Google Plus) o el reconocimiento de texto manuscrito en CAPTCHAs.
El camino que muchas de estas compañías siguen es el de utilizar distintos metodos numericos para el reconocimiento de imagenes basado en un entrenamiento inicial realizado por los mismos usuarios de las redes sociales o sistema en cuestion. Hace años que Facebook nos deja "etiquetar" a nuestros amigos y familiares, esto se hace seleccionando una región de la imagen (cuadrado) donde usualmente esta la cabeza de la persona - con este accionar se mejor la taza de acierto considerablemente.

En el contexto de la materia de métodos numéricos, aplicaremos un enfoque similar al comentado anteriormente pero con un dominio menor (cantidad y complejidad de imagenes acotados). Esto no significa que nos estamos alejando de escenarios reales pero si que lo restringimos por practicidad.
Dada una base de datos provista por la catedra con una gran cantidad de imágenes etiquetadas, intentaremos acertar cual es cual utilizando técnicas de Machine Learning - dichas tecnicas seran detalladas en los proximos parrafos.

Empezamos con la técnica \textbf{K vecinos más cercanos} (\textbf{kNN} dado las sigla en ingles k-nearest neighbor), a grandes rasgos podemos decir que teniendo un dominio de datos conocidos (etiquetados), se intenta de dar con aquellos que no tengan etiqueta utilizando para ello a los "vecinos". Se denominara "vecinos" a todo aquellos que estén más próximos a él en el espacio vectorial - esto se determina a través de la función de distancia. En dicha función las dimensiones del espacio están atadas al tamaño de la imagen, en nuestro caso $R^{784}$ esto se debe a que las imágenes son de 28x28 y cada pixel representa una coordenada del vector con el que se representa la misma.

Siguiendo por esta línea continuaremos con dos método de reducción de dimensiones: Análisis de componentes principales (PCA) y Análisis discriminante con cuadrados mínimos parciales (PLS-DA). Estos métodos son similares en cuanto a que realizan una transformación característica pero difieren en cuanto a la información original que se utiliza para dicha transformación. 
A diferencia de \textbf{KNN}, estos métodos no son de clasificación, si no que sirven para hacer una clasificación de nuestros datos de entrada. Por consecuente utilizaremos una combinación de estos métodos \textbf{KNN}+\textbf{PCA} y \textbf{KNN}+\textbf{PLSDA} para cumplir con nuestro objetivo.

Finalmente, realizaremos un análisis de dichas técnicas. Cabe aclarar que dado que nuestro conjunto de datos es relativamente inferior comparado al cual compañías como Google y Facebook trabajan a diario, los tiempos de computos seran considerablemente inferiores pero agregando la dificultad del tipo de imagenes que vamos a estar reconociendo. 
Para esto tilizaremos un método denominado Cross validation. Este procedimiento consiste en, dado un conjunto de imágenes se realiza una partición con el fin de entrenar nuestro algoritmo. Se realizara una división del conjunto dado, la primera mitad será para entrenamiento y la segunda mitad para realizar pruebas con el fin de corroborar la predicción realizada.
