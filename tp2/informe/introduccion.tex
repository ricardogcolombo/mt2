El objetivo de este trabajo práctico es desarollarar un clasificador que permita reconocer dígitos manuscritos.
Par llevarlo a cabo analizaremos técnicas de reconocimiento óptico de caracteres (OCR). Es un proceso dirigido a la digitalización de caracteres manuscritos, los cuales identifican automáticamente a partir de una imagen símbolos o caracteres que pertenecen a un determinado alfabeto, para luego almacenarlos en forma de datos.

Exploraremos la técnica de reconocimiento K-NN, K vecinos más próximos, además experimentaremos con distintas variantes de clasificación:

\begin{itemize}
\item PCA
\item PLSDA
\end{itemize}


Luego analizaremos la performance de cada una de estas técnicas mediante un set de experimentos, para evaluar las fortalezas y deficiencias de cada una de ellas. \\


\subsection{Introducción Teórica}


\subsubsection{Reconocimiento óptico de caracteres}


La tecnología de reconocimiento de caracteres, OCR (Optical Character  Recognition)  engloba  a  un  conjunto  de  téc
nicas basadas en  estadísticas, en las formas de los caracteres, transformadas y en comparaciones, que complementánd
ose entre sí, se  emplean para  distinguir de forma automática entre  los diferentes caracteres alfanuméricos existentes.
Enrealidad no se reconocen  exactamente los  caracteres de un determinado alfabeto, sino que es posible distinguir entre cualquier conjunto de formas o símbolos. Sin embargo, se debe tener en cuenta que la precisión que se obtiene en la práctica al inten
tar distinguir entre un conjunto de símbolos no es total. Por lo tanto, es fácil  deducir  que  cuanto  más  numeroso  es  el conjunto de símbolos entre los que se debe decidir, mayor es la probabilidad de que se produzca un fallo de clasificación. 
En todo sistema de reconocimiento óptico de caracteres se distinguen al menos estas 4 etapas: 

\begin{itemize}
\item Preproceso 
\item Segmentación 
\item Extracción de características 
\item Reconocimiento 
\end{itemize}


\subsubsubsection{Preproceso}

En esta fase de preprocesamiento (o adecuación de la imagen) el objetivo que se persigue es eliminar de la imagen de cualquier 
tipo de ruido o imperfección que no pertenezca al carácter, así como normalizar el tamaño del mismo. La normalización de la imagen también puede implicar un binarizado de la misma. Para la eliminación del ruido que puede aparecer en una imagen digital se utilizan diversos algoritmos:
\begin{itemize}
\item Etiquetado:  para  la  división  de  la  imagen  en  regiones  de componentes conectadas. 
\item Erosión / expansión: para la eliminación de peque\~nos grupos de píxeles. 
\item Umbralizado de histograma:  para  eliminar/seleccionar los objetos más brillantes o más oscuros de la imagen.  
\end{itemize}


\subsubsubsection{Segmentación}

Una vez preprocesada la imagen se deberá segmentar en las diferentes componentes conexas (parte de la imagen donde todos los píxeles son adyacentes entre sí) que la componen. La segmentación de la imagen constituye una de las mayores dificultades del reconocimiento, y se hace  necesaria para poder reconocer cada uno de los caracteres de la imagen binaria.
La fragmentación o segmentación es la operación que permite la descomposición  de  un  texto  en  diferentes  entidades lógicas. Estas entidades deben ser lo suficientemente invariables, para ser independientes del escritor, y lo suficientemente significativas para su reconocimiento.  


\subsubsubsection{Extracción de características}

Una  vez  realizada  la  segmentación,  se  tiene  una  imagen normalizada en la que se encuentra la información susceptible de ser “reconocida”. La información así representada, una matriz bidimensional de valores binarios.

La extracción de las características es una de las fases  más difíciles, dado que es muy difícil elegir un conjunto de características óptimo. 
Para que una característica se pueda considerar buena debe tener: 
\begin{itemize}
\item Discriminación: Deben  ser características que diferencien suficientemente una clase de otra
\item Deben tener igual valor para mismas clases 
\item Independencia: Las características deben estar incorreladas unas de otras. 
\item Pequeño espacio para características: El número de características debe ser pequeño para la rapidez y facilidad de clasificación. 
\end{itemize}

En este trabajo desarrollaremos y evaluaremos dos técnicas.


{\ttfamily PCA (Principal Component Analysis)} 

El objetivo de esta técnica es definir una transformación lineal desde el espacio de representación original a un nuevo espacio en el que las distintas clases de las muestras quedan mejor separadas.
Esta transformación permite reducir la dimensión del nuevo espacio sin perjudicar sensiblemente la capacidad discriminativa de la nueva representación. 

{\ttfamily PSL-DA (Partial Least Squares Discriminant Analysis)} 

Es un método estadístico que tiene relación con la regresión de componentes principales, se encuentra una regresión lineal mediante la proyección de las variables de predicción y las variables observables a un nuevo espacio. Debido a que tanto los datos de X e Y se proyectan a nuevos espacios, los familia de los modelos PLS se conoce como factor de modelos bilineales. Los cuadrados mínimos parciales Análisis discriminante (PLS-DA) es una variante que se utiliza cuando la Y es binaria.


\subsubsubsection{Reconocimiento}

Una  vez  se  tienen  las  características  más  importantes de la imagen a analizar hay que determinar el  carácter correspondiente en este trabajo exploraremos la técnica de KNN.


\subsubsection{ K-NN (K vecinos más próximos)}

Es un método no paramétrico y supervisado, que dado un conjunto de objetos prototipo de los que ya se conoce su clase (es decir, dado un conjunto de caracteres de muestra) y dado un  nuevo objeto cuya clase no conocemos (imagen de un carácter a reconocer) se busca entre el conjunto de prototipos los “k” más parecidos a nuevo objeto. A este se le asigna la clase más numerosa entre los “k” objetos prototipo seleccionados.  


\subsubsubsection{Entrenamiento y Test}


Conociendo el funcionamiento básico del método de clasificación de los “k vecinos más próximos” es obvio que para poder empezar a trabajar con este método es necesario reunir un conjunto de datos etiquetados, es decir, un conjunto de muestras prototipo con las clases a las que pertenecen. Esta recolección implica disponer de una base de datos de imágenes de los tipos de caracteres que posteriormente se esperen reconocer. A este conjunto de datos se le denomina conjunto de entrenamiento. Sin embargo, la fase de entrenamiento no solo consiste en la recopilación de estos datos, sino que, típicamente, los datos originales que se dedican al 
entrenamiento deben ser preprocesados adecuadamente para obtener representaciones compactas y coherentes. Esto quiere decir que  las  imágenes deben ser segmentadas, normalizadas y transformadas para obtener los vectores de baja dimensionalidad que finalmente se almacenan como conjunto de entrenamiento.
Con este conjunto de entrenamiento ya construido, el clasificador “knn” ya puede ser utilizado para reconocer la clase de una nueva muestra. Esta es la fase de test y lógicamente, también aquí es necesario aplicar todo el preproceso descrito anteriormente a cada una de las nuevas muestras. Por lo tanto, aquí se ve la necesidad de disponer de métodos rápidos de realizar estas tareas de preproceso, puesto que la velocidad de reconocimiento dependerá, en parte, de ellos. En la práctica se tiene que este preproceso es posible realizarlo muy rápidamente, aunque justo a continuación aparece la parte del proceso de reconocimiento que normalmente más carga computacional conlleva, la clasificación. 



