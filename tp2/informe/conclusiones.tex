\section{Conclusiones}
El análisis realizado nos lleva a sacar una serie de conclusiones en base a lo experimentado.

En primer lugar podemos mencionar que tanto para $PCA$ y $PLSDA$ manejamos valores relativamente chicos, deberiamos de ver que sucederia si es que seguimos aumentando estos valores. De igual manera por mas de que los valores eran relativamente chicos 
los tiempos de ejecucion son previsibles debido a la cantidad de iteraciones que pueden realizar los algoritmos y a el tamaño de la entrada.

\\
El algoritmo KNN presenta una gran efectividad, entendiendo que es una técnica que cuenta con varios años de antiguedad. Sin embargo, los tiempos necesarios para todas las comparaciones resultan considerablemente elevados.
Como dato importante de destacar, entendemos que la efectividad de este algoritmo depende en gran medidad de la variación de los datos a analizar. En aquellos conjuntos donde la varianza es elevada y los datos se encuentran muy dispersos, promediar el resultado en base a sus vecinos más cercanos puede no resultar la mejor técnica a implementar. Lo mismo podria ocurrir en situaciones donde los datos se ``asemejen''  demasiado por la elección de las características a medir (situación que podría mitigarse eligiendo nuevas formas de representar los datos o realizando un preprocesamiento previo a estos).

\\
Teniendo en cuenta esto, la relación costo-beneficio de la implementación y ejecución previa de una optimización como la de los algoritmos de $PCA$ o de $PLSDA$, resulta mínima. Si bien es cierto que, como pudimos observar en el análisis, se pierde una efectividad, atribuimos este comportamiento a algunas de los supuestos que mencionamos que asumían los algoritmos.

Sin embargo, dada la característica principal de los algoritmos de $PCA$ y $PLS-DA$ (ordenar las componentes principales en base a su relevancia), se permite ajustar la cantidad de datos a considerar, dando lugar a una mejora mas que considerable en la performance de aplicar sobre estos el algoritmo $KNN$ y el uso de memoria. Como vimos durante nuestro análisis, la cantidad óptima está bastante por debajo del máximo y no tienen ningún beneficio considerar una mayor cantidad de estas.

\\
Como resultado de esta característica, los tiempos de análisis se reducen drasticamente, todavía lejos de poder implementar este tipo de soluciones en ``tiempo real'' pero mucho más cercanos que utilizando solo el algoritmo de $KNN$.
\\
Como se menciona al comienzo del trabajo y de este apartado, el preprocesamiento de las imágenes es otro factor que puede mejorar la eficiencia algorítmica. Así como $PCA$ y $PLS-DA$ quitan ruido del dataset, es posible homogeneizar las imágenes por separado aplicando otros filtros.
\\
Si bien el propósito del trabajo busca encontrar dígitos en imágenes este mecanismo se puede utilizar de un modo muy parecido para encontrar otras características tanto en imágenes como en audios y así etiquetar según clases que no tienen que ver necesariamente con la extracción de dígitos.