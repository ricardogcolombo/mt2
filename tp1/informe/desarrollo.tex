\subsection{Porcentaje de Victorias}

Primero analizaremos la técnica que se basa a el \textbf{Porcentaje de Victorias}, que a lo largo del análisis denominaremos \textbf{WP},la misma analiza la performance de un equipo o participante en los partidos jugados en base a partidos ganados para el armado del ranking, digamos que si queremos generar el ranking 

La implementación consiste en calcular el ranking R ordenado de mayor a menor donde en cada posición $j$ del ranking se encuentra: R_j = $\sum_{i=1}^n{} \frac{G_i}{T}$. 

Donde \textbf{n} es la cantidad de partidos jugados, \textbf{$G_i$} corresponde a partidos ganados por el equipo $i$ y \textbf{$T_i$} al total de partidos jugados por el equipo $i$. \\

En este caso el score de un equipo no es afectado por la cantidad de partidos y resultados obtenidos de los demás participantes, pero esto si afecta su posición final en el ranking, además cada partido perdido para el equipo le hace perder valor en el ranking ya que el dividendo es mayor.

Mostremos esto con un ejemplo entre 3 equipos para ver como se ve afectado:
Supongamos que tenemos 3 equipos \textbf{A}, \textbf{B} y \textbf{C} al principio, como ninguno disputo ningún partido todos tienen valor 0 en la tabla de posiciones.

Ahora supongamos la siguiente de partidos y veamos cómo queda la tabla de posiciones

\begin{itemize}
\item \textbf{A} vs \textbf{B} $=>$ GANA \textbf{A} 
\item \textbf{A} vs \textbf{C} $=>$ GANA \textbf{C} 
\end{itemize}
\\
\begin{center}
    \begin{tabular}{| 1 | 1 | 1 |}
    \hline
    Posición & Equipo & Ranking \\ \hline
    1 & C & 1 \\ \hline
    2 & A & 1/2  \\ \hline
    3 & B & 0 \\ 
    \hline
    \end{tabular}
\end{center}

Como puede observarse en la tabla el equipo \textbf{B} quedo ultimo ya que no gano ningún partido y la diferencia entre el equipo \textbf{A} y el equipo \textbf{C} es la cantidad de partidos jugados, ya que ambos ganaron la misma cantidad pero como mencionamos anteriormente como el dividendo es más grande hace que el equipo \textbf{C} quede mejor posicionado.
Veamos que sucede si juegan el equipo \textbf{B} vs equipo \textbf{C} y gana el equipo \textbf{B}.

\begin{center}
    \begin{tabular}{| 1 | 1 | 1 |}
    \hline
    Posición & Equipo & Ranking \\ \hline
    1 & C & 1/2 \\ \hline
    2 & A & 1/2  \\ \hline
    3 & B & 1/2 \\
    \hline
    \end{tabular}
\end{center}

Como podemos observar todos quedan con igual ranking y esto es ya que todos jugaron la misma cantidad de partidos y ganaron la misma cantidad de partidos.

Con este ejemplo se puede observar lo que mencionamos anteriormente, que si bien los partidos de los demás no afectan a cambiar el valor de un equipo dentro del ranking si puede afectar su posición, a su vez esta técnica no aporta mucha información respecto a la posibilidad de victoria en el siguiente encuentro y tampoco considera el ranking del rival enfrentado, con lo cual la posición del equipo en el ranking depende de los resultados de victorias del equipo. Por otro lado podemos ver que nunca mencionamos los empates con este método, por ende podríamos analizar como podríamos modelarlos y como afectaría el ranking.

\subsection{Sistema a resolver}
Veamos qué pasa con él con el otro método para obtener rankings para poder comparar y ver cual nos parece más justo a la hora de utilizarlos para competencias reales.
Comencemos armando el sistema de la Matriz de Colley basados en el paper de Colley\footnote{''\textbf{The Colley Matrix Explained}:Wesley N. Colley''}, este método está basado en la Regla de Laplace de sucesos y solo se requiere conocer un historial de partidos. 
El método de \textbf{CMM} propone construir una matriz C $\in$ $ R^{nxn}$ , un vector b $\in$ $ R^n$ tal que el ranking r $\in$ $R^n$ buscado sea la solución al sistema :

\hfill $Cr=b$ \hfill \stackon{}{\textbf{(1)}}

\\
Construyamos la matriz $C$ del sistema, primero hagamos algunas definiciones, sea un equipo $i$, definamos como la cantidad total de partidos jugados por este equipo como $n_i$, por otro lado $w_i$ como la cantidad victorias el equipo, análogamente $l_i$ los partidos perdidos y por ultimo $n_{i,j}$ la cantidad de partidos jugados entre el equipo $i$ y $j$, finalmente las posiciones de la matriz $C$ se completan con: 

\[ C_{i,j} =
    \begin{cases}
        -n_{i,j}       & \quad \text{si }  \text{$i$ $\neq$ $j$} \\
        2+n_i & \quad \text{si } \text{$i$ $=$ $j$ }\\
    \end{cases}\hfill \stackon{}{\textbf{(2)}}
$$
  $$  \]
                    
y para el vector resultante $b$ definimos para el equipo $i$, $b_i$ = 1 +  ($w_i$ - $l_i$) / 2.

Esta matriz, tiene la particularidad de ser simétrica y definida positiva, siendo esta una condición suficiente para poder obtener la factorización de Cholesky, esta factorización se trata del producto de una matriz inferior por la traspuesta de dicha matriz inferior. Por lo tanto podremos utilizar este método para la resolución del sistema \textbf{(1)} que planteamos arriba. A su vez sabemos que esta matriz no necesita pivoteo si aplicamos el algoritmo de eliminación gaussiana, ya que todos sus elementos en la diagonal son positivos y distinto de cero, por lo que utilizaremos ambos métodos para la resolución del sistema \textbf{(1)}. Estos temas los veremos más en detalle en las siguientes subsecciones.
    
Volviendo a las características del método de CMM, a simple vista podemos ver que al igual que en $WP$ no se tiene en cuenta el margen de victoria, no modela los empates y tampoco nos da indicio de como impactara en el ranking cada uno de los resultados de los partidos. Por lo que en la sección de experimentos, veremos si con este método importa contra quien se gana y contra quien se pierde basándonos en las posiciones y analizaremos que pasara con los empates.

Nuestra intuición nos dice que importa más a quien se le gana, pensamos que no es lo mismo ganarle al que esta último que ganarle al que esta primero y en esto nos vamos a basar para realizar nuestras experimentaciones en las secciones de más adelante, para esto utilizaremos un algoritmo greedy tomando al equipo que salga último en el ranking y haciéndolo jugar con otro equipo que este mejor posicionado que él, utilizaremos 2 heurísticas distintas con el fin de obtener una mejor posición, la primera será contra el inmediato siguiente en el ranking y la otra contra el que este primero, siempre tomando el ranking que resulta luego de cada partido.


\subsubsection{Eliminación Gaussiana}

El algoritmo de Eliminación Gaussiana es útil para la resolución de sistemas lineales, con el cual mediante combinaciones lineales entre filas e intercambio  llegar a una matriz escalonada por reglones con ceros debajo de los elementos de la diagonal.\\
Finalmente, dado que la matriz esta triangulada, mediante el algoritmo denominado back substitution se realiza el cálculo para obtener el valor de las incógnitas tomando cada elemento como\\

\begin{center}
$x_i = (b_i - \sum\limits_{j = i + 1}^n c_{ij}x_i) / c_{ii}$ \\
\end{center}

Con el fin de obtener la solución al sistema \\
\begin{center}
$Cr=b$
\end{center}

Donde $C$ es la Matriz de Colley, con el fin de obtener el vector $r$ mostrado anteriormente en la ecuación del sistema a resolver. 

Dado que la matriz no contiene ninguna característica especifica que nos pueda acelerar la ejecución del mismo, con esto nos referimos a que puede no contener ceros debajo de la diagonal, y dado a que esta matriz es definida positiva como mencionamos anteriormente sabemos que en la diagonal nunca nos vamos a encontrar con un 0, por lo que en el algoritmo nos vamos a saltear esa validación,
si quisiéramos validar esto basta con tomar un vector canónico y ver si se cumple la definición de definida positiva.

A continuación presentamos un pseudo código del algoritmo de eliminación gaussiana que utilizamos en nuestra implementación, para el mismo tomamos como base el seudocódigo del libro de Burden \footnote{''\textbf{Análisis Numérico }:Richard L. Burden & J. Douglas Faires''},

\begin{algorithm}
    \begin{algorithmic}[1]\parskip=2mm  
        \caption{vector Gauss(matriz A, vector b)}
        \STATE{Para $k$=$1...n-1$}\\
        \STATE{\quad Para $i$=$1...n-1$}\\
        \STATE{\quad\quad Se toma el elemento $a_{k,k}$ como pivot}\\
        \STATE{\quad\quad Para $j = i+1,...n$}\\
        \STATE{\quad \quad \quad $a_{i,j}  = a_{i,j} - a_{i,j} * (a_{i,k} / a_{k,k})$}\\
        \STATE{\quad \quad \quad $b_{i}  = b_{i} - a_{i,j} * (a_{i,k} / a_{k,k})$}\\
        \STATE{return backwardSubstitution(A,b)}
    \end{algorithmic}
\end{algorithm}


\begin{algorithm}
    \begin{algorithmic}[1]\parskip=2mm
        \caption{vector backSubstitution(matriz A, vector b)}
        \STATE{$x = vector(Cantidad_Columnas(A))$}\\
        \STATE{$x_{n} = a_{n,n+1}/a_{n,n}$}\\
        \STATE{para $i=n-1..1$}\\
        \STATE{\quad para $j=i+1..n$}\\
        \STATE{\quad\quad $ sum +=a_{i,j}*x_{j}$}\\
        \STATE{\quad $x_i = \frac{(b_i -sum}{a_{i,i}}$}
        \STATE{\RETURN $x$}\\
    \end{algorithmic}
\end{algorithm}

Este algoritmo tiene complejidad temporal de $O(n^{3})$ para la eliminación Gaussiana y $O(n^{2})$ para el algoritmo de back substitution dando un total de $O(n^{3})$ como consto temporal para obtener una solución a nuestro sistema de ecuaciones lineales.

\newpage
\subsubsection{Cholesky}
La Matriz del sistema a resolver cuenta, como mencionamos anteriormente, tiene la propiedad de ser simétrica y definida positiva. Estas condiciones nos garantizan que la misma tenga otra factorización que represente un caso particular de la factorización $LU$, del tipo $C=LL^{t}$, esta se denomina la factorización de Cholesky, compuesta por una matriz Triangular inferior $L$ y la transpuesta de la misma matriz $L^{t}$. Donde las posiciones de esta matriz están compuestas de esta manera

$l_{ji} =
\left\{
    \begin{array}{lcc}
        \sqrt{c{_i}{_i} - \sum\limits_{k=1}^{i-1} (L_{ik})^2} & si & i = j \\
        \\ \frac{c_{ji} - \sum\limits_{k=1}^{i-1} L_{jk}l_{ik}}{l_{ii}} & si & i \neq j \\
    \end{array}
\right.$ \\

Una vez obtenido el sistema $LL^tx=b$ se procede a hacer back substituion para resolver $L^tx=y$, luego mediante forward substitution se obtiene la solución de $Ly=b$.

La implementación de la factorización de Cholesky que elegimos, al igual que la eliminación gaussiana, se encuentra en el libro \textbf{Burden}.
Este seudocódigo representa nuestra implementación sobre la factorización de Cholesky.

\begin{algorithm}
    \begin{algorithmic}[1]\parskip=2mm
        \caption{vector Cholesky(matriz A, vector b)}
        \STATE{$l_{1,1} = \sqrt{a_{1,1}}$}\\
        \STATE{Para j = 2,...n}
        \STATE{\quad $ l_{j,1} = a_{j,1} / l_{1,1}$}
        \STATE{Para $i = 2,...n-1$}\\
        \STATE{\quad $l_{i,i}  = (a_{i,i} - \sum_{k=1}^{i-1}{l^2_{i,k}}^{1/2})$}\\
        \STATE{\quad Para $j = i+1,...n1$}\\
        \STATE{\quad\quad $l_{j,i}  = (a_{j,i} - \sum_{k=1}^{i-1}{l_{j,k} l_{i,k}} / l_{i,i})$}\\
        \STATE{$l_{n,n}  = (a_{n,n} - \sum_{k=1}^{n-1}{l^2_{n,k}}$)}\\
        \STATE{y $=$ backSubstitution(L,b)}
        \STATE{x = forwardSubstitution(L,y)}
        \STATE{return x}
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}
    \begin{algorithmic}[1]\parskip=2mm
        \caption{vector forwardSubstitution(matriz L, vector b)}
        \STATE{$y_1=\frac{b_1}{l_{1,1}}$}\\ 
        \STATE{Para i$=$2..n}\\
        \STATE{\quad Para j$=$1..i-1}\\
        \STATE{\quad\quad sum=$l_{i,j}*y_j$}\\
        \STATE{\quad\quad $y_i=\frac{b_i-sum}{l_{i,i}}$}\\
        \STATE{return y}
      \end{algorithmic}
\end{algorithm}

Este algoritmo tiene complejidad temporal de $O(n^3)$ para Cholesky y $O(n^2)$ para los métodos de forward substitution y back substitution, quedando un total de $O(n^3)$.

\newpage